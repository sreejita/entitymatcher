{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This IPython notebook explains a basic workflow two tables using py_entitymatching. Our goal is to come up with a workflow to match books from Amazon and Walmart sites. Specifically, we want to achieve precision of at least 90% and recall as high as possible.  The datasets contain information about books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import py_entitymatching as em\n",
    "import pandas as pd\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the input tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    }
   ],
   "source": [
    "A = em.read_csv_metadata('amazon_books_utf8.csv')\n",
    "B = em.read_csv_metadata('walmart_books_utf8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A['id'] = range(0, len(A))\n",
    "em.set_key(A, 'id')\n",
    "B['id'] = range(0, len(B))\n",
    "em.set_key(B, 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep1 = '–'\n",
    "sep2 = ':'\n",
    "sep3 = ')'\n",
    "sep4 = '('\n",
    "A['Name'] = A['Name'].apply(lambda x: x.split(sep1, 1)[0])\n",
    "A['Name'] = A['Name'].apply(lambda x: x.split(sep2, 1)[0])\n",
    "A['Name'] = A['Name'].apply(lambda x: x.split(sep3, 1)[0])\n",
    "A['Name'] = A['Name'].apply(lambda x: x.replace(sep4, ''))\n",
    "A['Publisher'] = A['Publisher'].apply(lambda x: x.split(sep4, 1)[0])\n",
    "B['Name'] = B['Name'].apply(lambda x: x.split(sep2, 1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocking to generate candidate pairs\n",
    "We are applying the following blockers to get rid of obvious non-matches\n",
    "1. Black box blocker: To ensure single word book Names are not pruned away by overlap blocker\n",
    "2. Overlap blocker : We use overlap blocker on Author and then Name  with overlap size 2\n",
    "3. Rule-based blocker: We use rule-based blocker on Pages and Sale Price so that their absolute norm is less than 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:12\n"
     ]
    }
   ],
   "source": [
    "def name_similarity(x, y):\n",
    "    if len(x['Name'].split()) == 1 and len(y['Name'].split()) == 1:\n",
    "        if x['Name'].lower().strip() == y['Name'].lower().strip():\n",
    "            return False\n",
    "    return True\n",
    "# BlackBox Rules\n",
    "bb = em.BlackBoxBlocker()\n",
    "bb.set_black_box_function(name_similarity)\n",
    "C1 = bb.block_tables(A, B, l_output_attrs=['Name', 'Sale Price', 'Category', 'Author', 'ISBN10', 'Pages', 'Publisher', 'Language', 'Dimensions', 'Weight', 'Rating'], r_output_attrs=['Name', 'Sale Price', 'Category', 'Author', 'ISBN10', 'Pages', 'Publisher', 'Language', 'Dimensions', 'Weight', 'Rating'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#Overlap Rules\n",
    "ob = em.OverlapBlocker()\n",
    "ob.stop_words.append('of')\n",
    "C2 = ob.block_tables(A, B, 'Author', 'Author',word_level=True, overlap_size=2, l_output_attrs=['Name', 'Sale Price', 'Category', 'Author', 'ISBN10', 'Pages', 'Publisher', 'Language', 'Dimensions', 'Weight', 'Rating'], r_output_attrs=['Name', 'Sale Price', 'Category', 'Author', 'ISBN10', 'Pages', 'Publisher', 'Language', 'Dimensions', 'Weight', 'Rating'] )\n",
    "#C1 = ob.block_tables(A, B, 'Author', 'Author',word_level=True, overlap_size=2, l_output_attrs=['Name', 'Author', 'ISBN10'], r_output_attrs=['Name','Author', 'ISBN10'] )\n",
    "C3 = ob.block_candset(C2, 'Name', 'Name',overlap_size=2,word_level=True, rem_stop_words=True)\n",
    "C4 = em.combine_blocker_outputs_via_union([C1,C3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column Weight does not seem to qualify as any atomic type. It may contain all NaNs. Please update the values of column Weight\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#Rule based Rules\n",
    "block_f = em.get_features_for_blocking(A, B, validate_inferred_attr_types=False)\n",
    "rb = em.RuleBasedBlocker()\n",
    "rb.add_rule(['Pages_Pages_anm(ltuple, rtuple) < 0.8'], block_f)\n",
    "C5 = rb.block_candset(C4, show_progress=True)\n",
    "rb.add_rule(['Sale_Price_Sale_Price_anm(ltuple, rtuple) < 0.68'], block_f)\n",
    "C5 = rb.block_candset(C5, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C5.to_csv('blocked_pairs.csv', index = False, sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug blocker output\n",
    "We observe that the current blocker sequence does not drop obvious potential matches, and we can proceed with the matching step now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " dbg = em.debug_blocker(C5, A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>ltable_id</th>\n",
       "      <th>rtable_id</th>\n",
       "      <th>ltable_Name</th>\n",
       "      <th>ltable_Category</th>\n",
       "      <th>ltable_Author</th>\n",
       "      <th>ltable_ISBN10</th>\n",
       "      <th>ltable_Publisher</th>\n",
       "      <th>ltable_Language</th>\n",
       "      <th>ltable_Dimensions</th>\n",
       "      <th>ltable_Weight</th>\n",
       "      <th>rtable_Name</th>\n",
       "      <th>rtable_Category</th>\n",
       "      <th>rtable_Author</th>\n",
       "      <th>rtable_ISBN10</th>\n",
       "      <th>rtable_Publisher</th>\n",
       "      <th>rtable_Language</th>\n",
       "      <th>rtable_Dimensions</th>\n",
       "      <th>rtable_Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>979</td>\n",
       "      <td>2346</td>\n",
       "      <td>Babylon's Ashes The Expanse</td>\n",
       "      <td>Books &gt; Science Fiction &amp; Fantasy &gt; Science Fiction</td>\n",
       "      <td>James S. A. Corey</td>\n",
       "      <td>316217646</td>\n",
       "      <td>Orbit; Reprint edition</td>\n",
       "      <td>English</td>\n",
       "      <td>6 x 1.5 x 9.2 inches</td>\n",
       "      <td>1.3 pounds</td>\n",
       "      <td>The Expanse</td>\n",
       "      <td>Books &gt; Literature &amp; Fiction &gt; Fiction &gt; Science Fiction &amp; Fantasy &gt; Science Fiction &gt; Action &amp; ...</td>\n",
       "      <td>James S. A. Corey</td>\n",
       "      <td>6311296</td>\n",
       "      <td>Orbit</td>\n",
       "      <td>English</td>\n",
       "      <td>9.25 x 6.00 x 4.75 Inches (US)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1952</td>\n",
       "      <td>2346</td>\n",
       "      <td>Nemesis Games The Expanse</td>\n",
       "      <td>Books &gt; Science Fiction &amp; Fantasy &gt; Science Fiction</td>\n",
       "      <td>James S. A. Corey</td>\n",
       "      <td>316334715</td>\n",
       "      <td>Orbit; Reprint edition</td>\n",
       "      <td>English</td>\n",
       "      <td>6 x 1.5 x 9.2 inches</td>\n",
       "      <td>1.4 pounds</td>\n",
       "      <td>The Expanse</td>\n",
       "      <td>Books &gt; Literature &amp; Fiction &gt; Fiction &gt; Science Fiction &amp; Fantasy &gt; Science Fiction &gt; Action &amp; ...</td>\n",
       "      <td>James S. A. Corey</td>\n",
       "      <td>6311296</td>\n",
       "      <td>Orbit</td>\n",
       "      <td>English</td>\n",
       "      <td>9.25 x 6.00 x 4.75 Inches (US)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>342</td>\n",
       "      <td>2346</td>\n",
       "      <td>The Expanse Boxed Set</td>\n",
       "      <td>Books &gt; Science Fiction &amp; Fantasy &gt; Science Fiction</td>\n",
       "      <td>James S. A. Corey</td>\n",
       "      <td>316311294</td>\n",
       "      <td>Orbit; Box edition</td>\n",
       "      <td>English</td>\n",
       "      <td>6 x 4.8 x 9.2 inches</td>\n",
       "      <td>4.8 pounds</td>\n",
       "      <td>The Expanse</td>\n",
       "      <td>Books &gt; Literature &amp; Fiction &gt; Fiction &gt; Science Fiction &amp; Fantasy &gt; Science Fiction &gt; Action &amp; ...</td>\n",
       "      <td>James S. A. Corey</td>\n",
       "      <td>6311296</td>\n",
       "      <td>Orbit</td>\n",
       "      <td>English</td>\n",
       "      <td>9.25 x 6.00 x 4.75 Inches (US)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id  ltable_id  rtable_id                  ltable_Name  \\\n",
       "0    0        979       2346  Babylon's Ashes The Expanse   \n",
       "1    1       1952       2346    Nemesis Games The Expanse   \n",
       "2    2        342       2346        The Expanse Boxed Set   \n",
       "\n",
       "                                       ltable_Category      ltable_Author  \\\n",
       "0  Books > Science Fiction & Fantasy > Science Fiction  James S. A. Corey   \n",
       "1  Books > Science Fiction & Fantasy > Science Fiction  James S. A. Corey   \n",
       "2  Books > Science Fiction & Fantasy > Science Fiction  James S. A. Corey   \n",
       "\n",
       "  ltable_ISBN10         ltable_Publisher ltable_Language  \\\n",
       "0     316217646  Orbit; Reprint edition          English   \n",
       "1     316334715  Orbit; Reprint edition          English   \n",
       "2     316311294      Orbit; Box edition          English   \n",
       "\n",
       "      ltable_Dimensions ltable_Weight  rtable_Name  \\\n",
       "0  6 x 1.5 x 9.2 inches    1.3 pounds  The Expanse   \n",
       "1  6 x 1.5 x 9.2 inches    1.4 pounds  The Expanse   \n",
       "2  6 x 4.8 x 9.2 inches    4.8 pounds  The Expanse   \n",
       "\n",
       "                                                                                       rtable_Category  \\\n",
       "0  Books > Literature & Fiction > Fiction > Science Fiction & Fantasy > Science Fiction > Action & ...   \n",
       "1  Books > Literature & Fiction > Fiction > Science Fiction & Fantasy > Science Fiction > Action & ...   \n",
       "2  Books > Literature & Fiction > Fiction > Science Fiction & Fantasy > Science Fiction > Action & ...   \n",
       "\n",
       "       rtable_Author rtable_ISBN10 rtable_Publisher rtable_Language  \\\n",
       "0  James S. A. Corey       6311296            Orbit         English   \n",
       "1  James S. A. Corey       6311296            Orbit         English   \n",
       "2  James S. A. Corey       6311296            Orbit         English   \n",
       "\n",
       "                rtable_Dimensions  rtable_Weight  \n",
       "0  9.25 x 6.00 x 4.75 Inches (US)            NaN  \n",
       "1  9.25 x 6.00 x 4.75 Inches (US)            NaN  \n",
       "2  9.25 x 6.00 x 4.75 Inches (US)            NaN  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbg.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching tuple pairs in the candidate set\n",
    "In this step, we would want to match the tuple pairs in the candidate set. Specifically, we use learning-based method for matching purposes. This typically involves the following steps:\n",
    "\n",
    "1. Sampling and labeling the candidate set\n",
    "2. Splitting the labeled data into development and evaluation set\n",
    "3. Selecting the best learning based matcher using the development set\n",
    "4. Evaluating the selected matcher using the evaluation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling and labeling the candidate set\n",
    "First, we randomly sample 300 tuple pairs for labeling purposes.<br>\n",
    "Next, we label the sampled candidate set. Specify we would enter 1 for a match and 0 for a non-match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column name (gold_labels) is not present in dataframe\n"
     ]
    }
   ],
   "source": [
    "S = em.sample_table(C5, 300)\n",
    "G = em.label_table(S, label_column_name='gold_labels')\n",
    "G.to_csv('labeled_data.csv', index = False, sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, we have already labelled a sample of 300 from the blocked pairs, we will just load that into this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_G = 'labeled_data_300.csv'\n",
    "G = em.read_csv_metadata(path_G,key='_id',low_memory=False,ltable=A, rtable=B, \n",
    "                         fk_ltable='ltable_id', fk_rtable='rtable_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the labeled data into development and evaluation set\n",
    "In this step, we split the labeled data into two sets: development (I) and evaluation (J). Specifically, the development set is used to come up with the best learning-based matcher and the evaluation set used to evaluate the selected matcher on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test = em.split_train_test(G, train_proportion=0.5,random_state=0)\n",
    "I = train_test['train']\n",
    "J = train_test['test']\n",
    "\n",
    "I.to_csv('train.csv')\n",
    "J.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the best learning-based matcher\n",
    "Selecting the best learning-based matcher typically involves the following steps:\n",
    "\n",
    "1. Creating features\n",
    "2. Converting the development set into feature vectors\n",
    "3. Creating a set of learning-based matchers\n",
    "4. Selecting the best learning-based matcher using k-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating features\n",
    "Next, we need to create a set of features for the development set. Using automatic feature generation in py_entitymatching, set of features F is generated based on the attributes in the input tables.\n",
    "\n",
    "We removed features that take ‘id’, ‘Rating’ and ‘Dimensions’ as parameters from F as it does not contribute effectively to decide the matching between the tuple pairs in A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column Weight does not seem to qualify as any atomic type. It may contain all NaNs. Please update the values of column Weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table shows the corresponding attributes along with their respective types.\n",
      "Please confirm that the information  has been correctly inferred.\n",
      "If you would like to skip this validation process in the future,\n",
      "please set the flag validate_inferred_attr_types equal to false.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Left Attribute</th>\n",
       "      <th>Right Attribute</th>\n",
       "      <th>Left Attribute Type</th>\n",
       "      <th>Right Attribute Type</th>\n",
       "      <th>Example Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Name</td>\n",
       "      <td>Name</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sale Price</td>\n",
       "      <td>Sale Price</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>Exact Match; Absolute Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Category</td>\n",
       "      <td>Category</td>\n",
       "      <td>medium string (5 words to 10 words)</td>\n",
       "      <td>short string (1 word)</td>\n",
       "      <td>Not Applicable: Types do not match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Author</td>\n",
       "      <td>Author</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISBN10</td>\n",
       "      <td>ISBN10</td>\n",
       "      <td>short string (1 word)</td>\n",
       "      <td>short string (1 word)</td>\n",
       "      <td>Levenshtein Distance; Levenshtein Similarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pages</td>\n",
       "      <td>Pages</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>Exact Match; Absolute Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Publisher</td>\n",
       "      <td>Publisher</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Language</td>\n",
       "      <td>Language</td>\n",
       "      <td>short string (1 word)</td>\n",
       "      <td>short string (1 word)</td>\n",
       "      <td>Levenshtein Distance; Levenshtein Similarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dimensions</td>\n",
       "      <td>Dimensions</td>\n",
       "      <td>medium string (5 words to 10 words)</td>\n",
       "      <td>medium string (5 words to 10 words)</td>\n",
       "      <td>Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Weight</td>\n",
       "      <td>Weight</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>un-determined type</td>\n",
       "      <td>Not Applicable: Types do not match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rating</td>\n",
       "      <td>Rating</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>Exact Match; Absolute Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>id</td>\n",
       "      <td>id</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>Exact Match; Absolute Norm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Left Attribute Right Attribute                  Left Attribute Type  \\\n",
       "0            Name            Name     short string (1 word to 5 words)   \n",
       "1      Sale Price      Sale Price                              numeric   \n",
       "2        Category        Category  medium string (5 words to 10 words)   \n",
       "3          Author          Author     short string (1 word to 5 words)   \n",
       "4          ISBN10          ISBN10                short string (1 word)   \n",
       "5           Pages           Pages                              numeric   \n",
       "6       Publisher       Publisher     short string (1 word to 5 words)   \n",
       "7        Language        Language                short string (1 word)   \n",
       "8      Dimensions      Dimensions  medium string (5 words to 10 words)   \n",
       "9          Weight          Weight     short string (1 word to 5 words)   \n",
       "10         Rating          Rating                              numeric   \n",
       "11             id              id                              numeric   \n",
       "\n",
       "                   Right Attribute Type  \\\n",
       "0      short string (1 word to 5 words)   \n",
       "1                               numeric   \n",
       "2                 short string (1 word)   \n",
       "3      short string (1 word to 5 words)   \n",
       "4                 short string (1 word)   \n",
       "5                               numeric   \n",
       "6      short string (1 word to 5 words)   \n",
       "7                 short string (1 word)   \n",
       "8   medium string (5 words to 10 words)   \n",
       "9                    un-determined type   \n",
       "10                              numeric   \n",
       "11                              numeric   \n",
       "\n",
       "                                                                               Example Features  \n",
       "0   Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]  \n",
       "1                                                                    Exact Match; Absolute Norm  \n",
       "2                                                            Not Applicable: Types do not match  \n",
       "3   Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]  \n",
       "4                                                  Levenshtein Distance; Levenshtein Similarity  \n",
       "5                                                                    Exact Match; Absolute Norm  \n",
       "6   Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]  \n",
       "7                                                  Levenshtein Distance; Levenshtein Similarity  \n",
       "8   Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]  \n",
       "9                                                            Not Applicable: Types do not match  \n",
       "10                                                                   Exact Match; Absolute Norm  \n",
       "11                                                                   Exact Match; Absolute Norm  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to proceed? (y/n):y\n",
      "0                     Name_Name_jac_qgm_3_qgm_3\n",
      "1                 Name_Name_cos_dlm_dc0_dlm_dc0\n",
      "2                 Name_Name_jac_dlm_dc0_dlm_dc0\n",
      "3                                 Name_Name_mel\n",
      "4                            Name_Name_lev_dist\n",
      "5                             Name_Name_lev_sim\n",
      "6                                 Name_Name_nmw\n",
      "7                                  Name_Name_sw\n",
      "8                     Sale_Price_Sale_Price_exm\n",
      "9                     Sale_Price_Sale_Price_anm\n",
      "10               Sale_Price_Sale_Price_lev_dist\n",
      "11                Sale_Price_Sale_Price_lev_sim\n",
      "12                Author_Author_jac_qgm_3_qgm_3\n",
      "13            Author_Author_cos_dlm_dc0_dlm_dc0\n",
      "14            Author_Author_jac_dlm_dc0_dlm_dc0\n",
      "15                            Author_Author_mel\n",
      "16                       Author_Author_lev_dist\n",
      "17                        Author_Author_lev_sim\n",
      "18                            Author_Author_nmw\n",
      "19                             Author_Author_sw\n",
      "20                       ISBN10_ISBN10_lev_dist\n",
      "21                        ISBN10_ISBN10_lev_sim\n",
      "22                            ISBN10_ISBN10_jar\n",
      "23                            ISBN10_ISBN10_jwn\n",
      "24                            ISBN10_ISBN10_exm\n",
      "25                ISBN10_ISBN10_jac_qgm_3_qgm_3\n",
      "26                              Pages_Pages_exm\n",
      "27                              Pages_Pages_anm\n",
      "28                         Pages_Pages_lev_dist\n",
      "29                          Pages_Pages_lev_sim\n",
      "30          Publisher_Publisher_jac_qgm_3_qgm_3\n",
      "31      Publisher_Publisher_cos_dlm_dc0_dlm_dc0\n",
      "32      Publisher_Publisher_jac_dlm_dc0_dlm_dc0\n",
      "33                      Publisher_Publisher_mel\n",
      "34                 Publisher_Publisher_lev_dist\n",
      "35                  Publisher_Publisher_lev_sim\n",
      "36                      Publisher_Publisher_nmw\n",
      "37                       Publisher_Publisher_sw\n",
      "38                   Language_Language_lev_dist\n",
      "39                    Language_Language_lev_sim\n",
      "40                        Language_Language_jar\n",
      "41                        Language_Language_jwn\n",
      "42                        Language_Language_exm\n",
      "43            Language_Language_jac_qgm_3_qgm_3\n",
      "44        Dimensions_Dimensions_jac_qgm_3_qgm_3\n",
      "45    Dimensions_Dimensions_cos_dlm_dc0_dlm_dc0\n",
      "46                    Dimensions_Dimensions_mel\n",
      "47               Dimensions_Dimensions_lev_dist\n",
      "48                Dimensions_Dimensions_lev_sim\n",
      "49                            Rating_Rating_exm\n",
      "50                            Rating_Rating_anm\n",
      "51                       Rating_Rating_lev_dist\n",
      "52                        Rating_Rating_lev_sim\n",
      "53                                    id_id_exm\n",
      "54                                    id_id_anm\n",
      "55                               id_id_lev_dist\n",
      "56                                id_id_lev_sim\n",
      "Name: feature_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "F = em.get_features_for_matching(A, B)\n",
    "print (F.feature_name)\n",
    "F = F.drop(F.index[[44,45,46,47,48,49,50,51,52,53,54,55,56]])\n",
    "F = F.drop(F.index[[20,21,22,23,24,25]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the development set to feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>ltable_id</th>\n",
       "      <th>rtable_id</th>\n",
       "      <th>Name_Name_jac_qgm_3_qgm_3</th>\n",
       "      <th>Name_Name_cos_dlm_dc0_dlm_dc0</th>\n",
       "      <th>Name_Name_jac_dlm_dc0_dlm_dc0</th>\n",
       "      <th>Name_Name_mel</th>\n",
       "      <th>Name_Name_lev_dist</th>\n",
       "      <th>Name_Name_lev_sim</th>\n",
       "      <th>Name_Name_nmw</th>\n",
       "      <th>...</th>\n",
       "      <th>Publisher_Publisher_lev_sim</th>\n",
       "      <th>Publisher_Publisher_nmw</th>\n",
       "      <th>Publisher_Publisher_sw</th>\n",
       "      <th>Language_Language_lev_dist</th>\n",
       "      <th>Language_Language_lev_sim</th>\n",
       "      <th>Language_Language_jar</th>\n",
       "      <th>Language_Language_jwn</th>\n",
       "      <th>Language_Language_exm</th>\n",
       "      <th>Language_Language_jac_qgm_3_qgm_3</th>\n",
       "      <th>gold_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1064</td>\n",
       "      <td>1840</td>\n",
       "      <td>94</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>111</td>\n",
       "      <td>94</td>\n",
       "      <td>199</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>1268</td>\n",
       "      <td>2448</td>\n",
       "      <td>1016</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.877273</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>1208</td>\n",
       "      <td>2190</td>\n",
       "      <td>1977</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.614268</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>1336</td>\n",
       "      <td>2788</td>\n",
       "      <td>905</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      _id  ltable_id  rtable_id  Name_Name_jac_qgm_3_qgm_3  \\\n",
       "210  1064       1840         94                   0.027778   \n",
       "19    111         94        199                   1.000000   \n",
       "254  1268       2448       1016                   0.354167   \n",
       "241  1208       2190       1977                   0.161290   \n",
       "266  1336       2788        905                   0.441176   \n",
       "\n",
       "     Name_Name_cos_dlm_dc0_dlm_dc0  Name_Name_jac_dlm_dc0_dlm_dc0  \\\n",
       "210                       0.000000                       0.000000   \n",
       "19                        1.000000                       1.000000   \n",
       "254                       0.577350                       0.333333   \n",
       "241                       0.377964                       0.222222   \n",
       "266                       0.707107                       0.500000   \n",
       "\n",
       "     Name_Name_mel  Name_Name_lev_dist  Name_Name_lev_sim  Name_Name_nmw  \\\n",
       "210       0.563636                18.0           0.181818           -7.0   \n",
       "19        1.000000                 0.0           1.000000           17.0   \n",
       "254       0.877273                27.0           0.386364          -10.0   \n",
       "241       0.614268                33.0           0.250000           -9.0   \n",
       "266       0.900000                15.0           0.500000            0.0   \n",
       "\n",
       "        ...       Publisher_Publisher_lev_sim  Publisher_Publisher_nmw  \\\n",
       "210     ...                          0.233333                    -16.0   \n",
       "19      ...                          0.187500                      4.0   \n",
       "254     ...                          0.258065                    -15.0   \n",
       "241     ...                          0.464286                      4.0   \n",
       "266     ...                          0.333333                     -5.0   \n",
       "\n",
       "     Publisher_Publisher_sw  Language_Language_lev_dist  \\\n",
       "210                     6.0                         0.0   \n",
       "19                     14.0                         0.0   \n",
       "254                     7.0                         0.0   \n",
       "241                    10.0                         0.0   \n",
       "266                     7.0                         0.0   \n",
       "\n",
       "     Language_Language_lev_sim  Language_Language_jar  Language_Language_jwn  \\\n",
       "210                        1.0                    1.0                    1.0   \n",
       "19                         1.0                    1.0                    1.0   \n",
       "254                        1.0                    1.0                    1.0   \n",
       "241                        1.0                    1.0                    1.0   \n",
       "266                        1.0                    1.0                    1.0   \n",
       "\n",
       "     Language_Language_exm  Language_Language_jac_qgm_3_qgm_3  gold_labels  \n",
       "210                    1.0                                1.0            1  \n",
       "19                     1.0                                1.0            1  \n",
       "254                    1.0                                1.0            1  \n",
       "241                    1.0                                1.0            0  \n",
       "266                    1.0                                1.0            1  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F, \n",
    "                            attrs_after='gold_labels',\n",
    "                            show_progress=False) \n",
    "\n",
    "# Display first few rows\n",
    "H.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We imputed missing values for feature vectors with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(pd.notnull(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a set of learning-based matchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = em.DTMatcher(name='DecisionTree', random_state=0,max_depth=5)\n",
    "svm = em.SVMMatcher(name='SVM', random_state=0)\n",
    "rf = em.RFMatcher(name='RF', random_state=0)\n",
    "lg = em.LogRegMatcher(name='LogReg', random_state=0)\n",
    "ln = em.LinRegMatcher(name='LinReg')\n",
    "nb = em.NBMatcher(name='NaiveBayes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting the best matcher using cross-validation\n",
    "Now, we select the best matcher using 5-fold cross-validation. We need to obtain precision above 90% and maximize recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>Average recall</th>\n",
       "      <th>Average f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.865892</td>\n",
       "      <td>0.884073</td>\n",
       "      <td>0.873985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.905908</td>\n",
       "      <td>0.913625</td>\n",
       "      <td>0.908513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.735174</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.837992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>0.913085</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.925879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.922992</td>\n",
       "      <td>0.931411</td>\n",
       "      <td>0.925692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>0.861452</td>\n",
       "      <td>0.913625</td>\n",
       "      <td>0.886418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Matcher  Average precision  Average recall  Average f1\n",
       "0  DecisionTree           0.865892        0.884073    0.873985\n",
       "1            RF           0.905908        0.913625    0.908513\n",
       "2           SVM           0.735174        0.982609    0.837992\n",
       "3        LinReg           0.913085        0.941358    0.925879\n",
       "4        LogReg           0.922992        0.931411    0.925692\n",
       "5    NaiveBayes           0.861452        0.913625    0.886418"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_f1 = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "        exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        k=5,\n",
    "        target_attr='gold_labels', metric_to_select_matcher='f1', random_state=0)\n",
    "result_f1['cv_stats']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Debugging Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug X using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After debugging, we realised that a lot of false positives and false negatives were due to words like Paperback, Hardcover etc.  appearing the book 'Name'. We used a blackbox feature to address this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def name_name_feature(ltuple, rtuple):\n",
    "    n1 = ltuple.Name\n",
    "    n2 = rtuple.Name\n",
    "    n1 = n1.replace('Paperback','')\n",
    "    n1 = n1.replace('Hardcover','')\n",
    "    n1 = n1.replace('Mass Market','')\n",
    "    n1 = n1.replace('(','')\n",
    "    n1 = n1.replace(')','')\n",
    "    n2 = n2.replace('Paperback','')\n",
    "    n2 = n2.replace('Hardcover','')\n",
    "    n2 = n2.replace('Mass Market','')\n",
    "    n2 = n2.replace('(','')\n",
    "    n2 = n2.replace(')','')    \n",
    "    if n1 == n2:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column Weight does not seem to qualify as any atomic type. It may contain all NaNs. Please update the values of column Weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table shows the corresponding attributes along with their respective types.\n",
      "Please confirm that the information  has been correctly inferred.\n",
      "If you would like to skip this validation process in the future,\n",
      "please set the flag validate_inferred_attr_types equal to false.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Left Attribute</th>\n",
       "      <th>Right Attribute</th>\n",
       "      <th>Left Attribute Type</th>\n",
       "      <th>Right Attribute Type</th>\n",
       "      <th>Example Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Name</td>\n",
       "      <td>Name</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sale Price</td>\n",
       "      <td>Sale Price</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>Exact Match; Absolute Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Category</td>\n",
       "      <td>Category</td>\n",
       "      <td>medium string (5 words to 10 words)</td>\n",
       "      <td>short string (1 word)</td>\n",
       "      <td>Not Applicable: Types do not match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Author</td>\n",
       "      <td>Author</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISBN10</td>\n",
       "      <td>ISBN10</td>\n",
       "      <td>short string (1 word)</td>\n",
       "      <td>short string (1 word)</td>\n",
       "      <td>Levenshtein Distance; Levenshtein Similarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pages</td>\n",
       "      <td>Pages</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>Exact Match; Absolute Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Publisher</td>\n",
       "      <td>Publisher</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Language</td>\n",
       "      <td>Language</td>\n",
       "      <td>short string (1 word)</td>\n",
       "      <td>short string (1 word)</td>\n",
       "      <td>Levenshtein Distance; Levenshtein Similarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dimensions</td>\n",
       "      <td>Dimensions</td>\n",
       "      <td>medium string (5 words to 10 words)</td>\n",
       "      <td>medium string (5 words to 10 words)</td>\n",
       "      <td>Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Weight</td>\n",
       "      <td>Weight</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>un-determined type</td>\n",
       "      <td>Not Applicable: Types do not match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rating</td>\n",
       "      <td>Rating</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>Exact Match; Absolute Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>id</td>\n",
       "      <td>id</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>Exact Match; Absolute Norm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Left Attribute Right Attribute                  Left Attribute Type  \\\n",
       "0            Name            Name     short string (1 word to 5 words)   \n",
       "1      Sale Price      Sale Price                              numeric   \n",
       "2        Category        Category  medium string (5 words to 10 words)   \n",
       "3          Author          Author     short string (1 word to 5 words)   \n",
       "4          ISBN10          ISBN10                short string (1 word)   \n",
       "5           Pages           Pages                              numeric   \n",
       "6       Publisher       Publisher     short string (1 word to 5 words)   \n",
       "7        Language        Language                short string (1 word)   \n",
       "8      Dimensions      Dimensions  medium string (5 words to 10 words)   \n",
       "9          Weight          Weight     short string (1 word to 5 words)   \n",
       "10         Rating          Rating                              numeric   \n",
       "11             id              id                              numeric   \n",
       "\n",
       "                   Right Attribute Type  \\\n",
       "0      short string (1 word to 5 words)   \n",
       "1                               numeric   \n",
       "2                 short string (1 word)   \n",
       "3      short string (1 word to 5 words)   \n",
       "4                 short string (1 word)   \n",
       "5                               numeric   \n",
       "6      short string (1 word to 5 words)   \n",
       "7                 short string (1 word)   \n",
       "8   medium string (5 words to 10 words)   \n",
       "9                    un-determined type   \n",
       "10                              numeric   \n",
       "11                              numeric   \n",
       "\n",
       "                                                                               Example Features  \n",
       "0   Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]  \n",
       "1                                                                    Exact Match; Absolute Norm  \n",
       "2                                                            Not Applicable: Types do not match  \n",
       "3   Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]  \n",
       "4                                                  Levenshtein Distance; Levenshtein Similarity  \n",
       "5                                                                    Exact Match; Absolute Norm  \n",
       "6   Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]  \n",
       "7                                                  Levenshtein Distance; Levenshtein Similarity  \n",
       "8   Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]  \n",
       "9                                                            Not Applicable: Types do not match  \n",
       "10                                                                   Exact Match; Absolute Norm  \n",
       "11                                                                   Exact Match; Absolute Norm  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to proceed? (y/n):y\n"
     ]
    }
   ],
   "source": [
    "#Adding black box feature\n",
    "feature_table = em.get_features_for_matching(A, B)\n",
    "em.add_blackbox_feature(feature_table, 'name_name_feature', name_name_feature)\n",
    "feature_table = feature_table.drop(feature_table.index[[44,45,46,47,48,49,50,51,52,53,54,55,56]])\n",
    "feature_table = feature_table.drop(feature_table.index[[20,21,22,23,24,25]])\n",
    "H1 =em.extract_feature_vecs(I, feature_table=feature_table, attrs_after='gold_labels', show_progress=False)\n",
    "#H1.head(3)\n",
    "any(pd.notnull(H1))\n",
    "H1.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>Average recall</th>\n",
       "      <th>Average f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.891979</td>\n",
       "      <td>0.875378</td>\n",
       "      <td>0.881589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.933495</td>\n",
       "      <td>0.911807</td>\n",
       "      <td>0.921787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.735174</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.837992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>0.913085</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.925879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.922992</td>\n",
       "      <td>0.931411</td>\n",
       "      <td>0.925692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>0.891861</td>\n",
       "      <td>0.895048</td>\n",
       "      <td>0.892097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Matcher  Average precision  Average recall  Average f1\n",
       "0  DecisionTree           0.891979        0.875378    0.881589\n",
       "1            RF           0.933495        0.911807    0.921787\n",
       "2           SVM           0.735174        0.982609    0.837992\n",
       "3        LinReg           0.913085        0.941358    0.925879\n",
       "4        LogReg           0.922992        0.931411    0.925692\n",
       "5    NaiveBayes           0.891861        0.895048    0.892097"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H1, \n",
    "        exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        k=5,\n",
    "        target_attr='gold_labels', metric_to_select_matcher='f1', random_state=0)\n",
    "result['cv_stats']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the matching output\n",
    "Evaluating the matching outputs for the evaluation set typically involves the following four steps:\n",
    "\n",
    "1. Converting the evaluation set to feature vectors\n",
    "2. Training matcher using the feature vectors extracted from the development set\n",
    "3. Predicting the evaluation set using the trained matcher\n",
    "4. Evaluating the predicted matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the evaluation set to feature vectors\n",
    "As before, we convert to the feature vectors (using the feature table and the evaluation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = em.extract_feature_vecs(J, feature_table=feature_table,\n",
    "                            attrs_after='gold_labels', show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "any(pd.notnull(L))\n",
    "L.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the selected matcher\n",
    "Now, we train the matcher using all of the feature vectors from the development set. We use Random Forest as the selected matcher as it is giving highest precision and recall above 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using feature vectors from I using random forest\n",
    "rf.fit(table=H1, \n",
    "       exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting the matches\n",
    "Next, we predict the matches for the evaluation set (using the feature vectors extracted from it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on L \n",
    "predictions = rf.predict(table=L, exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "                         append=True,target_attr='predicted_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the predictions\n",
    "Finally, we evaluate the accuracy of predicted outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 91.01% (81/89)\n",
      "Recall : 84.38% (81/96)\n",
      "F1 : 87.57%\n",
      "False positives : 8 (out of 89 positive predictions)\n",
      "False negatives : 15 (out of 61 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'gold_labels', 'predicted_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training all matchers on I and applying to J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 90.0% (81/90)\n",
      "Recall : 84.38% (81/96)\n",
      "F1 : 87.1%\n",
      "False positives : 9 (out of 90 positive predictions)\n",
      "False negatives : 15 (out of 60 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I using decision tree\n",
    "dt.fit(table=H1, \n",
    "       exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions_dt = dt.predict(table=L, exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold_labels', 'predicted_labels'], \n",
    "                         append=True,target_attr='predicted_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions_dt, 'gold_labels', 'predicted_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 89.36% (84/94)\n",
      "Recall : 87.5% (84/96)\n",
      "F1 : 88.42%\n",
      "False positives : 10 (out of 94 positive predictions)\n",
      "False negatives : 12 (out of 56 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I using logistic regression\n",
    "lg.fit(table=H1, \n",
    "       exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions_lg = lg.predict(table=L, exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold_labels', 'predicted_labels'], \n",
    "                         append=True,target_attr='predicted_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions_lg, 'gold_labels', 'predicted_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 88.3% (83/94)\n",
      "Recall : 86.46% (83/96)\n",
      "F1 : 87.37%\n",
      "False positives : 11 (out of 94 positive predictions)\n",
      "False negatives : 13 (out of 56 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I using linear regression\n",
    "ln.fit(table=H1, \n",
    "       exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions_ln = ln.predict(table=L, exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold_labels', 'predicted_labels'], \n",
    "                         append=True,target_attr='predicted_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions_ln, 'gold_labels', 'predicted_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 85.0% (85/100)\n",
      "Recall : 88.54% (85/96)\n",
      "F1 : 86.73%\n",
      "False positives : 15 (out of 100 positive predictions)\n",
      "False negatives : 11 (out of 50 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I using Naive Bayes\n",
    "nb.fit(table=H1, \n",
    "       exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions_nb = nb.predict(table=L, exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold_labels', 'predicted_labels'], \n",
    "                         append=True,target_attr='predicted_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions_nb, 'gold_labels', 'predicted_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 72.18% (96/133)\n",
      "Recall : 100.0% (96/96)\n",
      "F1 : 83.84%\n",
      "False positives : 37 (out of 133 positive predictions)\n",
      "False negatives : 0 (out of 17 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I using SVM\n",
    "svm.fit(table=H1, \n",
    "       exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions_svm = svm.predict(table=L, exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold_labels', 'predicted_labels'], \n",
    "                         append=True,target_attr='predicted_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions_svm, 'gold_labels', 'predicted_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
